LLM_API_KEY=""
LLM_API_BASE="https://api.siliconflow.cn/v1"
# LLM_API_BASE="https://open.bigmodel.cn/api/paas/v4/"
JINA_API_KEY="" #for the search tool
PRIMARY_MODEL="THUDM/GLM-4-9B-0414"
# PRIMARY_MODEL="glm-z1-flash"
# PRIMARY_MODEL="THUDM/GLM-4-32B-0414"
# PRIMARY_MODEL="glm-4-air-250414"
SECONDARY_MODEL="THUDM/GLM-Z1-9B-0414"
# SECONDARY_MODEL="glm-4-flash-25041" 
# SECONDARY_MODEL="THUDM/GLM-Z1-32B-0414"
#use a secondary model to excute the filtering task for the cost saving
#if not set, will use the primary model to excute the filtering task
VL_MODEL="Pro/Qwen/Qwen2.5-VL-7B-Instruct"
# VL_MODEL="glm-4v-flash"
# your pb superuser account and password
PB_SUPERUSER_EMAIL="test@example.com"
PB_SUPERUSER_PASSWORD="1234567890"  #no '&' in the password and at least 10 characters
PROJECT_DIR="./core/work_dir"

# belowing is optional, go as you need
# for detail log info. If not need, remove this item.
# VERBOSE="true"
# for concurrent llm requests, make sure your llm provider supports it(leave default is 1)
# LLM_CONCURRENT_NUMBER=8
